{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn \n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>393.45000</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2    3      4      5     6       7    8      9   \\\n",
       "0       0.00632  18.00   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1     396.90000   4.98  24.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "2       0.02731   0.00   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "3     396.90000   9.14  21.60  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "4       0.02729   0.00   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "...         ...    ...    ...  ...    ...    ...   ...     ...  ...    ...   \n",
       "1007  396.90000   5.64  23.90  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "1008    0.10959   0.00  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "1009  393.45000   6.48  22.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "1010    0.04741   0.00  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "1011  396.90000   7.88  11.90  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "\n",
       "        10  \n",
       "0     15.3  \n",
       "1      NaN  \n",
       "2     17.8  \n",
       "3      NaN  \n",
       "4     17.8  \n",
       "...    ...  \n",
       "1007   NaN  \n",
       "1008  21.0  \n",
       "1009   NaN  \n",
       "1010  21.0  \n",
       "1011   NaN  \n",
       "\n",
       "[1012 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "boston_uri = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "\n",
    "raw_df = pd.read_csv(boston_uri, sep=\"\\s+\", skiprows=22, header=None)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0      1      2    3      4      5     6       7    8      9   \\\n",
      "0       0.00632  18.00   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1     396.90000   4.98  24.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
      "2       0.02731   0.00   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "3     396.90000   9.14  21.60  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
      "4       0.02729   0.00   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "...         ...    ...    ...  ...    ...    ...   ...     ...  ...    ...   \n",
      "1007  396.90000   5.64  23.90  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
      "1008    0.10959   0.00  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
      "1009  393.45000   6.48  22.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
      "1010    0.04741   0.00  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
      "1011  396.90000   7.88  11.90  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
      "\n",
      "        10  \n",
      "0     15.3  \n",
      "1      NaN  \n",
      "2     17.8  \n",
      "3      NaN  \n",
      "4     17.8  \n",
      "...    ...  \n",
      "1007   NaN  \n",
      "1008  21.0  \n",
      "1009   NaN  \n",
      "1010  21.0  \n",
      "1011   NaN  \n",
      "\n",
      "[1012 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "boston = raw_df\n",
    "print(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1012 entries, 0 to 1011\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       1012 non-null   float64\n",
      " 1   1       1012 non-null   float64\n",
      " 2   2       1012 non-null   float64\n",
      " 3   3       506 non-null    float64\n",
      " 4   4       506 non-null    float64\n",
      " 5   5       506 non-null    float64\n",
      " 6   6       506 non-null    float64\n",
      " 7   7       506 non-null    float64\n",
      " 8   8       506 non-null    float64\n",
      " 9   9       506 non-null    float64\n",
      " 10  10      506 non-null    float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 87.1 KB\n"
     ]
    }
   ],
   "source": [
    "boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1012.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>180.143778</td>\n",
       "      <td>12.008350</td>\n",
       "      <td>16.834792</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>188.132839</td>\n",
       "      <td>17.250728</td>\n",
       "      <td>9.912616</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.257830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.021000</td>\n",
       "      <td>7.240000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>391.435000</td>\n",
       "      <td>16.780000</td>\n",
       "      <td>21.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>396.900000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2           3           4   \\\n",
       "count  1012.000000  1012.000000  1012.000000  506.000000  506.000000   \n",
       "mean    180.143778    12.008350    16.834792    0.069170    0.554695   \n",
       "std     188.132839    17.250728     9.912616    0.253994    0.115878   \n",
       "min       0.006320     0.000000     0.460000    0.000000    0.385000   \n",
       "25%       0.257830     0.000000     8.375000    0.000000    0.449000   \n",
       "50%      24.021000     7.240000    18.100000    0.000000    0.538000   \n",
       "75%     391.435000    16.780000    21.890000    0.000000    0.624000   \n",
       "max     396.900000   100.000000    50.000000    1.000000    0.871000   \n",
       "\n",
       "               5           6           7           8           9           10  \n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000  \n",
       "mean     6.284634   68.574901    3.795043    9.549407  408.237154   18.455534  \n",
       "std      0.702617   28.148861    2.105710    8.707259  168.537116    2.164946  \n",
       "min      3.561000    2.900000    1.129600    1.000000  187.000000   12.600000  \n",
       "25%      5.885500   45.025000    2.100175    4.000000  279.000000   17.400000  \n",
       "50%      6.208500   77.500000    3.207450    5.000000  330.000000   19.050000  \n",
       "75%      6.623500   94.075000    5.188425   24.000000  666.000000   20.200000  \n",
       "max      8.780000  100.000000   12.126500   24.000000  711.000000   22.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\ai course\\Fundamental Natural Lenguage Processing\\2 Linear & Logistic Regression\\practice.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m boston[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "boston['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 5 fields in line 28, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\ai course\\Fundamental Natural Lenguage Processing\\2 Linear & Logistic Regression\\practice.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m boston_uri \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttp://lib.stat.cmu.edu/datasets/humandevel\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(boston_uri, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms+\u001b[39;49m\u001b[39m\"\u001b[39;49m, skiprows\u001b[39m=\u001b[39;49m\u001b[39m22\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1749\u001b[0m         nrows\n\u001b[0;32m   1750\u001b[0m     )\n\u001b[0;32m   1751\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 5 fields in line 28, saw 7\n"
     ]
    }
   ],
   "source": [
    "boston_uri = \"http://lib.stat.cmu.edu/datasets/humandevel\"\n",
    "\n",
    "data = pd.read_csv(boston_uri, sep=\"\\s+\", skiprows=22)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.44</td>\n",
       "      <td>103</td>\n",
       "      <td>56.6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1866.99</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>133.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.84</td>\n",
       "      <td>96</td>\n",
       "      <td>55.3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1850.64</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>107.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.48</td>\n",
       "      <td>127</td>\n",
       "      <td>53.1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1743.04</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>62.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.43</td>\n",
       "      <td>126</td>\n",
       "      <td>54.8</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1709.30</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>83.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.99</td>\n",
       "      <td>101</td>\n",
       "      <td>57.2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1689.60</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>61.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.76</td>\n",
       "      <td>96</td>\n",
       "      <td>57.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1806.31</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>61.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.32</td>\n",
       "      <td>93</td>\n",
       "      <td>57.2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2136.37</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>83.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.32</td>\n",
       "      <td>88</td>\n",
       "      <td>57.2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.92</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>79.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.6</td>\n",
       "      <td>94</td>\n",
       "      <td>55.8</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1966.81</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>97.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.62</td>\n",
       "      <td>85</td>\n",
       "      <td>57.2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2154.67</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>99.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.03</td>\n",
       "      <td>97</td>\n",
       "      <td>57.2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1767.56</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>81.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.59</td>\n",
       "      <td>114</td>\n",
       "      <td>56.5</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1827.92</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>88.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.52</td>\n",
       "      <td>113</td>\n",
       "      <td>59.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1773.83</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>79.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.67</td>\n",
       "      <td>124</td>\n",
       "      <td>58.5</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1971.63</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>72.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Therese</td>\n",
       "      <td>Stukel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dartmouth</td>\n",
       "      <td>Hitchcock</td>\n",
       "      <td>Medical</td>\n",
       "      <td>Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>One</td>\n",
       "      <td>Medical</td>\n",
       "      <td>Center</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lebanon</td>\n",
       "      <td>NH</td>\n",
       "      <td>03756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>e-mail:</td>\n",
       "      <td>stukel@dartmouth.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                     1        2       3     4    5        6  \\\n",
       "0        7.44                   103     56.6       1   4.0  2.0  1866.99   \n",
       "1        6.84                    96     55.3       2   4.0  2.0  1850.64   \n",
       "2        6.48                   127     53.1       1   5.0  2.0  1743.04   \n",
       "3        6.43                   126     54.8       2   5.0  2.0  1709.30   \n",
       "4        7.99                   101     57.2       2   6.0  1.0  1689.60   \n",
       "5        8.76                    96     57.2       1   6.0  1.0  1806.31   \n",
       "6        6.32                    93     57.2       2   7.0  1.0  2136.37   \n",
       "7        6.32                    88     57.2       1   7.0  1.0  2018.92   \n",
       "8         7.6                    94     55.8       2   8.0  1.0  1966.81   \n",
       "9        7.62                    85     57.2       1   8.0  1.0  2154.67   \n",
       "10       6.03                    97     57.2       1   9.0  1.0  1767.56   \n",
       "11       6.59                   114     56.5       2   9.0  1.0  1827.92   \n",
       "12       7.52                   113     59.2       2  10.0  1.0  1773.83   \n",
       "13       7.67                   124     58.5       1  10.0  1.0  1971.63   \n",
       "14    Therese                Stukel      NaN     NaN   NaN  NaN      NaN   \n",
       "15  Dartmouth             Hitchcock  Medical  Center   NaN  NaN      NaN   \n",
       "16        One               Medical   Center     Dr.   NaN  NaN      NaN   \n",
       "17    Lebanon                    NH    03756     NaN   NaN  NaN      NaN   \n",
       "18    e-mail:  stukel@dartmouth.edu      NaN     NaN   NaN  NaN      NaN   \n",
       "\n",
       "         7        8  \n",
       "0   1051.0  133.358  \n",
       "1   1079.0  107.503  \n",
       "2   1034.0   62.143  \n",
       "3   1070.0   83.009  \n",
       "4   1173.0   61.236  \n",
       "5   1079.0   61.236  \n",
       "6   1067.0   83.916  \n",
       "7   1104.0   79.380  \n",
       "8   1347.0   97.524  \n",
       "9   1439.0   99.792  \n",
       "10  1029.0   81.648  \n",
       "11  1100.0   88.452  \n",
       "12  1204.0   79.380  \n",
       "13  1160.0   72.576  \n",
       "14     NaN      NaN  \n",
       "15     NaN      NaN  \n",
       "16     NaN      NaN  \n",
       "17     NaN      NaN  \n",
       "18     NaN      NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_uri = \"http://lib.stat.cmu.edu/datasets/IQ_Brain_Size\"\n",
    "\n",
    "raw_df = pd.read_csv(boston_uri, sep=\"\\s+\", skiprows=33, header=None)\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3.34</td>\n",
       "      <td>11.400</td>\n",
       "      <td>81.5</td>\n",
       "      <td>3243.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.00</td>\n",
       "      <td>921.870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>3.14</td>\n",
       "      <td>11.000</td>\n",
       "      <td>78.8</td>\n",
       "      <td>4281.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>57.00</td>\n",
       "      <td>997.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.21</td>\n",
       "      <td>9.800</td>\n",
       "      <td>81.6</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>895.696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>42.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.22</td>\n",
       "      <td>9.000</td>\n",
       "      <td>76.2</td>\n",
       "      <td>9699.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>14.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>911.817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>38.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.48</td>\n",
       "      <td>10.700</td>\n",
       "      <td>79.8</td>\n",
       "      <td>3451.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>954.442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3      4        5     6       7     8     9\n",
       "0    36.0  27.0  71.0   8.1   3.34   11.400  81.5  3243.0   8.8  42.6\n",
       "1    11.7  21.0  15.0  59.0  59.00  921.870   NaN     NaN   NaN   NaN\n",
       "2    35.0  23.0  72.0  11.1   3.14   11.000  78.8  4281.0   3.5  50.7\n",
       "3    14.4   8.0  10.0  39.0  57.00  997.875   NaN     NaN   NaN   NaN\n",
       "4    44.0  29.0  74.0  10.4   3.21    9.800  81.6  4260.0   0.8  39.4\n",
       "..    ...   ...   ...   ...    ...      ...   ...     ...   ...   ...\n",
       "115  14.0   7.0   3.0   8.0  56.00  895.696   NaN     NaN   NaN   NaN\n",
       "116  42.0  33.0  76.0   9.7   3.22    9.000  76.2  9699.0   4.8  42.2\n",
       "117  14.5   8.0   8.0  49.0  54.00  911.817   NaN     NaN   NaN   NaN\n",
       "118  38.0  28.0  72.0   8.9   3.48   10.700  79.8  3451.0  11.7  37.5\n",
       "119  13.0  14.0  13.0  39.0  58.00  954.442   NaN     NaN   NaN   NaN\n",
       "\n",
       "[120 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_uri = \"http://lib.stat.cmu.edu/datasets/pollution\"\n",
    "\n",
    "raw_df = pd.read_csv(boston_uri, sep=\"\\s+\", skiprows=22, header=None)\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREC</th>\n",
       "      <th>JANT</th>\n",
       "      <th>JULT</th>\n",
       "      <th>OVR65</th>\n",
       "      <th>POPN</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>HOUS</th>\n",
       "      <th>DENS</th>\n",
       "      <th>NONW</th>\n",
       "      <th>WWDRK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3.34</td>\n",
       "      <td>11.400</td>\n",
       "      <td>81.5</td>\n",
       "      <td>3243.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.00</td>\n",
       "      <td>921.870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>3.14</td>\n",
       "      <td>11.000</td>\n",
       "      <td>78.8</td>\n",
       "      <td>4281.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>57.00</td>\n",
       "      <td>997.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.21</td>\n",
       "      <td>9.800</td>\n",
       "      <td>81.6</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>895.696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>42.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.22</td>\n",
       "      <td>9.000</td>\n",
       "      <td>76.2</td>\n",
       "      <td>9699.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>14.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>911.817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>38.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.48</td>\n",
       "      <td>10.700</td>\n",
       "      <td>79.8</td>\n",
       "      <td>3451.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>954.442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PREC  JANT  JULT  OVR65   POPN     EDUC  HOUS    DENS  NONW  WWDRK\n",
       "0    36.0  27.0  71.0    8.1   3.34   11.400  81.5  3243.0   8.8   42.6\n",
       "1    11.7  21.0  15.0   59.0  59.00  921.870   NaN     NaN   NaN    NaN\n",
       "2    35.0  23.0  72.0   11.1   3.14   11.000  78.8  4281.0   3.5   50.7\n",
       "3    14.4   8.0  10.0   39.0  57.00  997.875   NaN     NaN   NaN    NaN\n",
       "4    44.0  29.0  74.0   10.4   3.21    9.800  81.6  4260.0   0.8   39.4\n",
       "..    ...   ...   ...    ...    ...      ...   ...     ...   ...    ...\n",
       "115  14.0   7.0   3.0    8.0  56.00  895.696   NaN     NaN   NaN    NaN\n",
       "116  42.0  33.0  76.0    9.7   3.22    9.000  76.2  9699.0   4.8   42.2\n",
       "117  14.5   8.0   8.0   49.0  54.00  911.817   NaN     NaN   NaN    NaN\n",
       "118  38.0  28.0  72.0    8.9   3.48   10.700  79.8  3451.0  11.7   37.5\n",
       "119  13.0  14.0  13.0   39.0  58.00  954.442   NaN     NaN   NaN    NaN\n",
       "\n",
       "[120 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_df\n",
    "\n",
    "data.columns = ['PREC', 'JANT', 'JULT', 'OVR65', 'POPN', 'EDUC', 'HOUS', 'DENS', 'NONW', 'WWDRK']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\ai course\\Fundamental Natural Lenguage Processing\\2 Linear & Logistic Regression\\practice.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "data['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "|details-start|\n",
      "**References**\n",
      "|details-split|\n",
      "\n",
      "- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "  Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "  Structure and Classification Rule for Recognition in Partially Exposed\n",
      "  Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "  Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "  on Information Theory, May 1972, 431-433.\n",
      "- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "  conceptual clustering system finds 3 classes in the data.\n",
      "- Many, many more ...\n",
      "\n",
      "|details-end|\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['data']\n",
    "target = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target[target<2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target[target == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_binary = target[target<2]\n",
    "features_binary = features[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features_binary\n",
    "y = target_binary\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logreg = LogisticRegression(random_state=1)\n",
    "model_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model_logreg.predict(X_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16\n",
       "0    14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precissio: 1.0\n",
      "Recall: 1.0\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred)}\")\n",
    "print(f\"Precissio: {precision_score(y_test, y_test_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred)}\")\n",
    "print(f\"Classification Report: {classification_report(y_test, y_test_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perpare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features \n",
    "y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    37\n",
       "0    36\n",
       "1    32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18\n",
       "0    14\n",
       "2    13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build The Model and Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logreg = LogisticRegression(random_state=1)\n",
    "model_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n",
      "Precision: 0.9793650793650793\n",
      "Recall: 0.9777777777777777\n",
      "F1 score: 0.9778718400940623\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred, average='weighted')}\")\n",
    "print(f\"F1 score: {f1_score(y_test, y_test_pred, average='weighted')}\")\n",
    "print(f\"Classification report:\\n{classification_report(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model_logreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9809523809523809\n",
      "Precision: 0.9819291819291819\n",
      "Recall: 0.9809523809523809\n",
      "F1 score: 0.9808957878567386\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_train, y_train_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_train, y_train_pred, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_train, y_train_pred, average='weighted')}\")\n",
    "print(f\"F1 score: {f1_score(y_train, y_train_pred, average='weighted')}\")\n",
    "print(f\"Classification report:\\n{classification_report(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'sklearn.datasets' from 'c:\\\\Users\\\\Hammam\\\\Lib\\\\site-packages\\\\sklearn\\\\datasets\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'sklearn.datasets' from 'c:\\\\Users\\\\Hammam\\\\Lib\\\\site-packages\\\\sklearn\\\\datasets\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sklearn.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linier Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cov = fetch_california_housing()\n",
    "data_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hous = data_cov\n",
    "\n",
    "data_hous['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_hous['data']\n",
    "target = data_hous['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   8.3252       41.            6.98412698 ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   8.3014       21.            6.23813708 ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   7.2574       52.            8.28813559 ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.7          17.            5.20554273 ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.8672       18.            5.32951289 ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   2.3886       16.            5.25471698 ...    2.61698113\n",
      "    39.37       -121.24      ]]\n",
      "[4.526 3.585 3.521 ... 0.923 0.847 0.894]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = features\n",
    "y = target\n",
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6192, 8)\n",
      "(14448, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14448, 6192]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\ai course\\Fundamental Natural Lenguage Processing\\2 Linear & Logistic Regression\\practice.ipynb Cell 56\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#Y110sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m lr \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#Y110sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m lr\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#Y110sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(y_train\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#Y110sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(X_train.shape)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ai%20course/Fundamental%20Natural%20Lenguage%20Processing/2%20Linear%20%26%20Logistic%20Regression/practice.ipynb#Y110sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# X_train.shape\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[39m=\u001b[39m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1166\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\Hammam\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14448, 6192]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(y_train.shape)\n",
    "# print(X_train.shape)\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = pd.DataFrame(features)\n",
    "tc = data.corr()\n",
    "sns.heatmap(tc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
